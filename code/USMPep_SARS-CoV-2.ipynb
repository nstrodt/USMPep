{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib  inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from proteomics_preprocessing import *\n",
    "from utils.proteomics_utils import *\n",
    "from mhc_analysis_utils import *\n",
    "\n",
    "from modelv1 import Model    \n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Requirements\n",
    "\n",
    "## MHC I data\n",
    "### MHCFlurry18 (BA) [ODonnell2018]\n",
    "Download curated MHC I dataset by [ODonnell2018] from https://data.mendeley.com/datasets/8pz43nvvxh/1/files/e1916ecf-b544-40e6-b1fe-e0024bea76a7/data_curated.20180219.tar.bz2?dl=1 and extract the archive in ./data\n",
    "\n",
    "### NetMhCpan4.0 (MS) [Jensen2018]\n",
    "From http://www.cbs.dtu.dk/suppl/immunology/NetMHCpan-4.0/ download 0th CV split files f000_ba (train) and c000_ba (val, 20%) store in data_dir/NetMHCpan_4_0_train.\n",
    "            \n",
    "\n",
    "## MHC II data\n",
    "\n",
    "### NetMHCIIpan3.2 (BA) [Jurtz2017]\n",
    "From www.cbs.dtu.dk/suppl/immunology/NetMHCIIpan-3.2/ download 1st CV split files train1 (train) and test1 (val) and store as train1.txt and test1.txt in ./data/NetMHCIIpan_3_2_train.\n",
    "            \n",
    "### NetMHCIIpan4.0 (MS) [Reynisson2020]\n",
    "Download http://www.cbs.dtu.dk/suppl/immunology/NAR_NetMHCpan_NetMHCIIpan/NetMHCIIpan_train.tar.gz, unpack and save as NetMHCIIpan_train in ./data.\n",
    "\n",
    "## Test data\n",
    "### Stability measurements for sars-cov-2 peptides [Prachar 2020]\n",
    "Download https://www.immunitrack.com/wp/wp-content/uploads/Covid19-Intavis-Immunitrack-datasetV2.xlsx and save in ./data directory.\n",
    "\n",
    "\n",
    "**References**\n",
    "- [ODonnell2018] T. J. O’Donnell, A. Rubinsteyn, M. Bonsack, A. B. Riemer, U. Laserson, and J. Hammerbacher, “MHCflurry: Open-Source Class I MHC Binding Affinity Prediction,” Cell Systems, vol. 7, no. 1, pp. 129–132.e4, Jul. 2018. [Online].\n",
    "Available: https://doi.org/10.1016/j.cels.2018.05.014\n",
    "\n",
    "- [Jurtz2017] Vanessa Jurtz, Sinu Paul, Massimo Andreatta, Paolo Marcatili, Bjoern Peters, and Morten Nielsen, NetMHCpan-4.0:  Improved peptide-MHC class I interaction predictions integrating eluted lig-and and peptide binding affinity data.Journal of immunology (Baltimore, Md. :  1950), 199(9):3360–3368, Nov 2017. ISSN 1550-6606. Available: https://doi.org/10.4049/jimmunol.1700893\n",
    "\n",
    "- [Jensen2018] Kamilla Kjærgaard Jensen, Massimo Andreatta, Paolo Marcatili, Søren Buus, Jason A. Greenbaum,Zhen Yan, Alessandro Sette, Bjoern Peters, and Morten Nielsen, Improved methods for predictingpeptide binding affinity to MHC class II molecules.Immunology, 154(3):394–406, 2018. Available: https://doi.org/10.1111/imm.12889\n",
    "\n",
    "- [Reynisson2020] Birkir Reynisson,  Bruno Alvarez,  Sinu Paul,  Bjoern Peters,  and Morten Nielsen,   NetMHCpan-4.1 and NetMHCIIpan-4.0:  improved predictions of MHC antigen presentation by concurrentmotif deconvolution and integration of MS MHC eluted ligand data.Nucleic Acids Research,48(W1):W449–W454, 05 2020.   ISSN 0305-1048.   doi:  10.1093/nar/gkaa379. Available: https://doi.org/10.1093/nar/gkaa379\n",
    "\n",
    "- [Prachar2020] Marek  Prachar,  Sune  Justesen,  Daniel  Bisgaard  Steen-Jensen,  Stephan  Thorgrimsen,  Erik  Jurgons,  Ole Winther, and Frederik OtzenBagger, Identification and validation of 174COVID-19 vaccine candidate epitopes reveals low performance of common epitope predictiontools. Scientific Reports, 10(1), Nov. 2020.  Available: https://doi.org/10.1038/s41598-020-77466-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Binding affinity dataset\n",
    "Create a directory for each dataset with subdirectories for each allele. The output of the preprocessing saved in each allele subdirectory is structured as follows:\n",
    "\n",
    "- *tok.npy* sequences as list of numerical indices (mapping is provided by *tok_itos.npy*)\n",
    "- *label.npy* label as list of binding affintiy values (mapping is provided by *label_itos.npy*)\n",
    "- *train_IDs.npy/val_IDs.npy/test_IDs.npy* numerical indices identifying training/validation/test set by specifying rows in tok.npy\n",
    "- *train_IDs_prev.npy/val_IDs_prev.npy/test_IDs_prev.npy* original non-numerical IDs for all entries that were ever assigned to the respective sets (used to obtain consistent splits for downstream tasks)\n",
    "- *ID.npy* original non-numerical IDs for all entries in tok.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path= Path(\"./reg_sars_cov_BA\")\n",
    "dataset_path.mkdir(exist_ok=True)\n",
    "\n",
    "# sheet titles in Covid19-Intavis-Immunitrack-datasetV2.xlsx corresponding to allele names \n",
    "# no BA data available for \"10 C0102\"\n",
    "allele_sheets = [\"1 A0101\",\n",
    "\"2 A0201\",\n",
    "\"3 A0301\",\n",
    "\"4 A1101\",\n",
    "\"5 A2402\",\n",
    "\"6 B4001\",\n",
    "\"7 C0401\",\n",
    "\"8 C0701\",\n",
    "\"9 C0702\",\n",
    "\n",
    "\"11 DRB10401\"]\n",
    "\n",
    "prep = Preprocess()\n",
    "for allele in allele_sheets:\n",
    "    prep.clas_mhc_sars_cov(allele, \"flurry\", working_folder=dataset_path/allele, pretrained_folder=\"../../USMPep/git_data/lm_netchop_peptides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass spectroscopy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path= Path(\"./reg_sars_cov_MS\")\n",
    "dataset_path.mkdir(exist_ok=True)\n",
    "\n",
    "# sheet titles in Covid19-Intavis-Immunitrack-datasetV2.xlsx corresponding to allele names\n",
    "# no MS data available for \"8 C0701\" and \"10 C0102\"\n",
    "allele_sheets = [\"1 A0101\",\n",
    "\"2 A0201\",\n",
    "\"3 A0301\",\n",
    "\"4 A1101\",\n",
    "\"5 A2402\",\n",
    "\"6 B4001\",\n",
    "\"7 C0401\",\n",
    "                 \n",
    "\"9 C0702\",\n",
    "\n",
    "\"11 DRB10401\"]\n",
    "\n",
    "prep = Preprocess()\n",
    "for allele in allele_sheets:\n",
    "    prep.clas_mhc_sars_cov(allele, \"netmhcpan4\", MS=True, working_folder=dataset_path/allele, pretrained_folder=\"../../USMPep/git_data/lm_netchop_peptides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream Training and Evaluation\n",
    "\n",
    "from_scratch is set to True for training from scratch and set to False for using a language model. By default we will use the provided language model that was pretrained on Netchop peptides (../git_data/lm_netchop_peptides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ensemble on BA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles = [\"1 A0101\",\n",
    "            \"2 A0201\",\n",
    "            \"3 A0301\",\n",
    "            \"4 A1101\",\n",
    "            \"5 A2402\",\n",
    "            \"6 B4001\",\n",
    "            \"7 C0401\",\n",
    "            \"8 C0701\",\n",
    "            \"9 C0702\",\n",
    "\n",
    "            \"11 DRB10401\"]\n",
    "\n",
    "data_dir = \"./reg_sars_cov_BA\"\n",
    "\n",
    "modelv1 = Model()\n",
    "\n",
    "allele_dir_list = [data_dir +\"/\" + a for a in alleles]\n",
    "n_alleles = len(allele_dir_list)\n",
    "\n",
    "for ensemble_i in range(10):\n",
    "    for clas_folder in allele_dir_list:\n",
    "        # Train\n",
    "        # model_filename_prefix should end on the ensemble index ensemble_i\n",
    "        modelv1.generic_model(working_folder=clas_folder, model_filename_prefix=\"USMPep_LM_BA_{}\".format(ensemble_i),\n",
    "                        from_scratch=False, \n",
    "                        pretrained_folder=\"../git_data/lm_netchop_peptides\",pretrained_model_filename=\"lm_1l_3_enc\",\n",
    "                        eval_on_test=True, export_preds=True,\n",
    "                        train=True,clas=True, regression=True, concat_train_val=True,\n",
    "                        emb_sz=50,nh=64,nl=1,\n",
    "                        bs=32, epochs=10, lr=0.05,\n",
    "                        wd=1e-7, dropout=0.1,\n",
    "                        interactive=False,\n",
    "                        metrics=[])\n",
    "        \n",
    "    # be careful to give the correct preds_filename. If eval_on_test=True, the test predictions are saved as \"preds_valid.npz\",\n",
    "    # if eval_on_val_test=True, the test predictions are saved as \"preds_test.npz\",\n",
    "    # val_on_test=True, the test predictions are saved as \"preds_valid.npz\"    \n",
    "    collect_preds_npz(data_dir, n_alleles, subfoldername=\"\", ensemble_i=ensemble_i, preds_filename='preds_valid.npz', \n",
    "                    ranked_alleles=False, allele_list=alleles)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ensemble on MS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles = [\"1 A0101\",\n",
    "            \"2 A0201\",\n",
    "            \"3 A0301\",\n",
    "            \"4 A1101\",\n",
    "            \"5 A2402\",\n",
    "            \"6 B4001\",\n",
    "            \"7 C0401\",\n",
    "           \n",
    "            \"9 C0702\",\n",
    "\n",
    "            \"11 DRB10401\"]\n",
    "\n",
    "data_dir = \"./reg_sars_cov_MS\"\n",
    "\n",
    "modelv1 = Model()\n",
    "\n",
    "allele_dir_list = [data_dir +\"/\" + a for a in alleles]\n",
    "n_alleles = len(allele_dir_list)\n",
    "\n",
    "for ensemble_i in range(5):\n",
    "    for clas_folder in allele_dir_list:\n",
    "        # Train\n",
    "        # model_filename_prefix should end on the ensemble index ensemble_i\n",
    "        modelv1.generic_model(working_folder=clas_folder, model_filename_prefix=\"USMPep_LM_MS_{}\".format(ensemble_i),\n",
    "                        from_scratch=False, \n",
    "                        pretrained_folder=\"../git_data/lm_netchop_peptides\",pretrained_model_filename=\"lm_1l_3_enc\",\n",
    "                        eval_on_test=True, export_preds=True,\n",
    "                        train=True,clas=True, regression=False, concat_train_val=True,\n",
    "                        emb_sz=50,nh=64,nl=1,\n",
    "                        bs=512, epochs=10, lr=0.05,\n",
    "                        wd=1e-7, dropout=0.1,\n",
    "                        interactive=False,\n",
    "                        metrics=[])\n",
    "        \n",
    "    # be careful to give the correct preds_filename. If eval_on_test=True, the test predictions are saved as \"preds_valid.npz\",\n",
    "    # if eval_on_val_test=True, the test predictions are saved as \"preds_test.npz\",\n",
    "    # val_on_test=True, the test predictions are saved as \"preds_valid.npz\"    \n",
    "    collect_preds_npz(data_dir, n_alleles, regression=False, subfoldername=\"\", ensemble_i=ensemble_i, preds_filename='preds_valid.npz', \n",
    "                    ranked_alleles=False, allele_list=alleles)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "To evaluate the predictions after an ensemble of models has been trained, load the *.npz files and compile model names, predictions, targets, sequences and allele names in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions and create ensembles\n",
    "results = []\n",
    "data_dirs = (\"./reg_sars_cov_BA\", \"./reg_sars_cov_MS\")\n",
    "\n",
    "agg_dic = {\"targs\": lambda x: x.iloc[0], \"preds\":np.mean}\n",
    "\n",
    "for data_dir in data_dirs:\n",
    "    # load predictions for all alleles per ensemble\n",
    "    ensemble = []\n",
    "    for f in Path(data_dir).glob(\"*.npz\"):\n",
    "        if \"BA\" in data_dir:\n",
    "            df_tmp = read_npz(f, ensemble=True,transform_targs=False, transform_preds=False, with_args=False)\n",
    "            ensemble.append(df_tmp)\n",
    "        elif \"MS\" in data_dir and \"MS\" in str(f):\n",
    "            df_tmp = read_npz(f, ensemble=True,transform_targs=False, transform_preds=False, sigmoid=False,\n",
    "                  with_args=False)\n",
    "            df_tmp[\"preds\"] = 1- df_tmp[\"preds\"] \n",
    "            ensemble.append(df_tmp)\n",
    "\n",
    "    # aggregate ensembles\n",
    "    ensemble = pd.concat(ensemble, ignore_index=True, sort=True)\n",
    "\n",
    "    # keep single model predictions\n",
    "    single = ensemble.copy()[['rank', 'ID', 'targs', 'preds', 'model']]\n",
    "    single = single.set_index([\"model\", \"rank\", \"ID\"])\n",
    "\n",
    "    # simply average predicitons for an ensemble predictor\n",
    "    ensemble[\"model\"] = ensemble[\"model\"].apply(lambda x: x[:-2])\n",
    "    ensemble= ensemble.groupby([\"model\", \"rank\", \"ID\"]).agg(agg_dic)\n",
    "\n",
    "    result = pd.concat([ensemble, single], sort=True)\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "results = pd.concat(results)\n",
    "\n",
    "# Create ensemble of BA regressors and MS classifiers (simple average)\n",
    "bams_ens_models = [\"USMPep_LM_BA_{}\".format(i) for i in range(5)] + [\"USMPep_LM_MS_{}\".format(i) for i in range(5)] \n",
    "# drop allele C0701 because no MS data is available\n",
    "bams_ens = results.loc[bams_ens_models].drop(\"8 C0701\", axis=0, level=1).reset_index()\n",
    "bams_ens[\"model\"] = \"USMPep_LM_BAMS\"\n",
    "bams_ens = bams_ens.groupby([\"model\", \"rank\", \"ID\"]).agg(agg_dic)\n",
    "results = pd.concat([results, bams_ens], sort=True)\n",
    "\n",
    "results = results.loc[[\"USMPep_LM_BA\",\"USMPep_LM_BAMS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aucroc_stability_targs(df, stability_threshold=60):\n",
    "    targs = (df[\"targs\"]>stability_threshold)*1.0\n",
    "    if targs.sum()>0 and targs.mean()<1:\n",
    "        return roc_auc_score((df[\"targs\"]>stability_threshold)*1.0, df[\"preds\"])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "scores = pd.DataFrame({\"AUC ROC\":results.groupby(level=[0,1]).apply(aucroc_stability_targs),\n",
    "                      \"Spearman r\":results.groupby(level=[0,1]).apply(spearmanr_eval, filter_quantitative=False)})\n",
    "           \n",
    "scores[\"AUC ROC\"].unstack().T.plot.bar(title=\"AUC ROC\")\n",
    "\n",
    "print(\"median Spearman r over alleles A*01:01, A*02:0, A*03:01, A*11:01, A*24:02, B*40:01, C*04:01, C*07:02, C*01:02:\")\n",
    "print(scores[\"Spearman r\"].drop([\"8 C0701\", \"11 DRB10401\"], axis=0, level=1).groupby(level=0).median())\n",
    "print(\"\\n\")\n",
    "print(\"median AUC ROC over alleles A*01:01, A*02:0, A*03:01, A*11:01, A*24:02, B*40:01:\")\n",
    "print(scores[\"AUC ROC\"].drop([\"7 C0401\",\n",
    "                                \"8 C0701\",\n",
    "                                \"9 C0702\",\n",
    "                                \"10 C0102\",\n",
    "                                \"11 DRB10401\"], axis=0, level=1).groupby(level=0).median())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:proteomics]",
   "language": "python",
   "name": "conda-env-proteomics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
